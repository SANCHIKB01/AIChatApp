AI Chat App (Flask + Groq + LangChain + FAISS)
An intelligent AI-powered web app that lets users ask questions based on uploaded documents (PDF/TXT) or have open-ended chats. It uses Groq's ultra-fast LLaMA 3 model and LangChain's Retrieval-Augmented Generation (RAG) pipeline with FAISS for document understanding.


ðŸš€ Features
- ðŸ” Upload `.pdf` or `.txt` files and ask questions about them
- ðŸ§  Powered by Groqâ€™s blazing-fast LLaMA 3 model
- ðŸ§° Uses LangChain and FAISS for document retrieval
- ðŸ§¾ Displays chat history and uploaded documents with delete buttons
- ðŸŒ Fully deployable on platforms like Render


ðŸ“¸ Screenshots
Project View
![image](https://github.com/user-attachments/assets/cc9f92ee-a726-4627-9811-330d3cd9e876)

Uploading File and QnA
![image](https://github.com/user-attachments/assets/1cac202d-7156-4f4c-873f-a01a0c7037c0)

Delete the document
![image](https://github.com/user-attachments/assets/adf5ff38-aa97-4866-b670-0634a91715dc)

MongoDB Chat messages
![image](https://github.com/user-attachments/assets/77555947-0de6-40ee-9f5a-ad1062b14d7f)

Redix Cache messages
![image](https://github.com/user-attachments/assets/ba52f197-0e0b-47af-8cdb-79a3b97d7b8c)


ðŸ› ï¸ Tech Stack
  Layer                 Tools Used                                      
 Frontend           Flask + Jinja2 Templates                        
 Backend            Python (Flask), LangChain, FAISS                
 LLM API            Groq LLaMA 3       
 Embeddings         HuggingFaceEmbeddings via LangChain             
 Storage            In-memory (No persistent DB required)           
                     

ðŸ“‚ Project Structure
ai-chat-app/
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ ask.html
â”‚ â””â”€â”€ base.html
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ database.py
â”‚ â””â”€â”€ rag_system.py
â”œâ”€â”€ screenshots/
â”‚ â”œâ”€â”€ upload.png
â”‚ â”œâ”€â”€ ask.png
â”‚ â””â”€â”€ history.png


ðŸ—£ï¸ Set Your API Keys 
> Before running the app, you need to generate two API keys:  
 1. Groq API Key from [console.groq.com](https://console.groq.com) â€” used to access the LLaMA model.  
 2. Hugging Face API Token from [huggingface.co](https://huggingface.co/settings/tokens) â€” used to create embeddings for the document text.
>These are added as environment variables named `GROQ_API_KEY` and `HUGGINGFACEHUB_API_TOKEN`.


ðŸŽ¥ Demo Video You can watch a full walkthrough here:  


ðŸ”— GitHUb Repo: https://github.com/SANCHIKB01/ai-chat-app

Local Setup
bash
git clone https://github.com/SANCHIKB01/ai-chat-app.git
cd ai-chat-app
pip install -r requirements.txt
python app.py




